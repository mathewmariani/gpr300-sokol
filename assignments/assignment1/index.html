<!DOCTYPE html><html lang="en" data-bs-theme="dark"> <head><base href="/gpr300-sokol/"><!-- global --><meta charset="utf-8"><meta name="viewport" content="width=device-width,initial-scale=1"><link rel="icon" type="image/png" href="/favicon.png"><link rel="sitemap" href="/sitemap-index.xml"><meta name="generator" content="Astro v5.1.8"><!-- bootstrap --><link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.3/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha384-QWTKZyjpPEjISv5WaRU9OFeRpok6YctnYmDr5pNlyT2bRjXh0JMhjY6hW+ALEwIH" crossorigin="anonymous"><link href="https://unpkg.com/@highlightjs/cdn-assets@11.7.0/styles/github-dark.min.css" rel="stylesheet"><!-- primary --><title>GPR-300</title><meta name="title" content="GPR-300"><meta name="description" content><!-- open graph --><meta property="og:type" content="website"><meta property="og:url" content="https://www.mathewmariani.com/gpr300-sokol/assignments/assignment1/"><meta property="og:title" content="GPR-300"><meta property="og:description" content><!-- <meta property="og:image" content={new URL(image, Astro.url)} /> --><!-- twitter --><meta property="twitter:card" content="summary_large_image"><meta property="twitter:url" content="https://www.mathewmariani.com/gpr300-sokol/assignments/assignment1/"><meta property="twitter:title" content="GPR-300"><meta property="twitter:description" content><!-- <meta property="twitter:image" content={new URL(image, Astro.url)} /> --><style>:root{--highlight-color: null;--highlight-background: null}::selection{background:var(--highlight-background)}.highlight{height:24px;position:relative;top:-28px;left:-10px;width:calc(100% + 10px);max-width:100vw;z-index:-1;border-radius:2px;background:var(--highlight-color)}ul li{list-style:none}ul>li:before{content:"‚û°Ô∏è";margin-right:8px}ol li{list-style:none}ol>li:before{margin-right:8px}ol>li:nth-child(1):before{content:"1Ô∏è‚É£"}ol>li:nth-child(2):before{content:"2Ô∏è‚É£"}ol>li:nth-child(3):before{content:"3Ô∏è‚É£"}ol>li:nth-child(4):before{content:"4Ô∏è‚É£"}ol>li:nth-child(5):before{content:"5Ô∏è‚É£"}ol>li:nth-child(6):before{content:"6Ô∏è‚É£"}ol>li:nth-child(7):before{content:"7Ô∏è‚É£"}ol>li:nth-child(8):before{content:"8Ô∏è‚É£"}ol>li:nth-child(9):before{content:"9Ô∏è‚É£"}ol>li:nth-child(10):before{content:"üîü"}pre{border-radius:8px;overflow:hidden;position:relative}details summary{cursor:pointer;list-style:none}details summary::marker{content:""}details summary:before{content:"‚ÑπÔ∏è";margin-right:8px}details[open] summary:before{content:"‚¨áÔ∏è"}
.demo[data-astro-cid-3cfzgy2g]{margin-right:auto;margin-left:auto;border:0;width:800px;height:600px;overflow:hidden;display:block;image-rendering:optimizeSpeed;image-rendering:-moz-crisp-edges;image-rendering:-o-crisp-edges;image-rendering:-webkit-optimize-contrast;image-rendering:optimize-contrast;image-rendering:crisp-edges;image-rendering:pixelated;-ms-interpolation-mode:nearest-neighbor}
</style></head> <body class="container" id="top"> <main> <article>  <h1>Assignment 1</h1> <div class="highlight"></div> <p class="lead">Framebuffers &amp; Postprocessing</p> <canvas class="demo" id="canvas" oncontextmenu="event.preventDefault()" data-astro-cid-3cfzgy2g></canvas> <script type="text/javascript">
  var Module = {
    preRun: [],
    postRun: [],
    print: (function () {
      return function (text) {
        text = Array.prototype.slice.call(arguments).join(" ");
        console.log(text);
      };
    })(),
    printErr: function (text) {
      text = Array.prototype.slice.call(arguments).join(" ");
      console.error(text);
    },
    canvas: (function () {
      var canvas = document.getElementById("canvas");
      canvas.addEventListener(
        "webglcontextlost",
        function (e) {
          alert("FIXME: WebGL context lost, please reload the page");
          e.preventDefault();
        },
        false,
      );
      return canvas;
    })(),
    setStatus: function (text) {},
    monitorRunDependencies: function (left) {},
  };
  window.onerror = function (event) {
    console.log("onerror: " + event.message);
  };
</script> <script type="text/javascript" src="demos/assignment1.js" async></script>  <h4 id="requirements">Requirements</h4>
<p>The goal of this assignment is to strengthen your understanding of framebuffers by implementing the following post-processing effects.</p>
<ol>
<li>A scene that contains, at minimum:
<ul>
<li>A 3D Model</li>
</ul>
</li>
<li>Implement a method to create a custom framebuffer
<ul>
<li>Framebuffer must contain at least one color buffer and one depth buffer.</li>
<li>Depth buffer can either be  a texture2D or rbo. If sampling depth buffer for your effect, use a texture2D. If not, use a renderbuffer object.</li>
</ul>
</li>
<li>Scene must be rendered to framebuffer</li>
<li>Render the framebuffer to the screen as a fullscreen quad or triangle, and apply a post process effect in the fragment shader.</li>
<li>Post process effect must include ImGUI controls for all relevant properties (enabled/disabled, intensity, etc)</li>
<li>Some possible effects:
<ul>
<li><a href="https://en.wikipedia.org/wiki/Kernel_(image_processing)">Box Blur</a></li>
<li><a href="https://en.wikipedia.org/wiki/Kernel_(image_processing)">Gaussian Blur</a></li>
<li><a href="https://en.wikipedia.org/wiki/Kernel_(image_processing)">Sharpen</a></li>
<li><a href="https://en.wikipedia.org/wiki/Kernel_(image_processing)">Edge Detection</a></li>
<li><a href="https://en.wikipedia.org/wiki/Tone_mapping">HDR Tone Mapping</a></li>
<li><a href="https://en.wikipedia.org/wiki/Gamma_correction">Gamma Correction</a></li>
<li><a href="https://en.wikipedia.org/wiki/Chromatic_aberration">Chromatic Aberration</a></li>
<li><a href="https://en.wikipedia.org/wiki/Vignetting">Vignette</a></li>
<li><a href="https://en.wikipedia.org/wiki/Distortion_(optics)">Lens Distortion</a></li>
<li><a href="https://en.wikipedia.org/wiki/Film_grain">Film grain</a></li>
<li><a href="https://en.wikipedia.org/wiki/Distance_fog">Screen-space Fog</a> (requires reading from depth buffer)</li>
</ul>
</li>
<li>Use version control best practices - descriptive commit messages, frequent commits, no extraneous files.</li>
</ol>
<p>Build off of the previous assignment to complete this one.</p>
<h4 id="instructions">Instructions</h4>
<ol>
<li>
<p>Shader Setup:</p>
<ul>
<li>Design a shader program that defines the visual transformation or manipulation you want to apply to the scene. This shader is responsible for determining the color of each pixel in the output.</li>
</ul>
</li>
<li>
<p>Framebuffer Setup:</p>
<ul>
<li>Set up a framebuffer object (FBO) to render the scene into a texture instead of the default frame buffer. This texture will serve as the input for the post-processing effect.</li>
</ul>
</li>
<li>
<p>Render the Scene to the Framebuffer:</p>
<ul>
<li>Render the entire scene to the framebuffer rather than the default frame buffer. This step is crucial for capturing the scene‚Äôs appearance as a texture.</li>
</ul>
</li>
<li>
<p>Bind the Default Framebuffer:</p>
<ul>
<li>Switch back to rendering to the default frame buffer for the final display.</li>
</ul>
</li>
<li>
<p>Activate the Post-Processing Shader:</p>
<ul>
<li>Use the fragment shader created as a post-processing shader. This shader reads the texture rendered to the framebuffer and applies the desired visual effect.</li>
</ul>
</li>
<li>
<p>Render a Quad:</p>
<ul>
<li>Render a fullscreen quad (two triangles forming a rectangle that covers the entire screen) using the post-processing shader. This quad will be textured with the result from the framebuffer, and the shader will apply the post-processing effect.</li>
</ul>
</li>
<li>
<p>Display the Result:</p>
<ul>
<li>Display the final result on the screen.</li>
</ul>
</li>
</ol>
<h3 id="supplementary-reading">Supplementary Reading</h3>
<ul>
<li><a href="https://learnopengl.com/Advanced-OpenGL/Framebuffers">LearnOpenGL - Framebuffers</a></li>
</ul>  </article> </main> <footer> <hr> <p class="text-center text-mutes">Made with <span id="with-love">‚ù§Ô∏è</span> in Montr√©al.</p> </footer>  <script src="/gpr300-sokol/sugar.js"></script> </body> </html> 